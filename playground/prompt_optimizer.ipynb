{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d31ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "META_PROMPT = \"\"\"\n",
    "Given a task description or existing prompt, produce a detailed system prompt to guide a language model in completing the task effectively.\n",
    "\n",
    "# Guidelines\n",
    "\n",
    "- Understand the Task: Grasp the main objective, goals, requirements, constraints, and expected output.\n",
    "- Minimal Changes: If an existing prompt is provided, improve it only if it's simple. For complex prompts, enhance clarity and add missing elements without altering the original structure.\n",
    "- Reasoning Before Conclusions**: Encourage reasoning steps before any conclusions are reached. ATTENTION! If the user provides examples where the reasoning happens afterward, REVERSE the order! NEVER START EXAMPLES WITH CONCLUSIONS!\n",
    "    - Reasoning Order: Call out reasoning portions of the prompt and conclusion parts (specific fields by name). For each, determine the ORDER in which this is done, and whether it needs to be reversed.\n",
    "    - Conclusion, classifications, or results should ALWAYS appear last.\n",
    "- Examples: Include high-quality examples if helpful, using placeholders [in brackets] for complex elements.\n",
    "   - What kinds of examples may need to be included, how many, and whether they are complex enough to benefit from placeholders.\n",
    "- Clarity and Conciseness: Use clear, specific language. Avoid unnecessary instructions or bland statements.\n",
    "- Formatting: Use markdown features for readability. DO NOT USE ``` CODE BLOCKS UNLESS SPECIFICALLY REQUESTED.\n",
    "- Preserve User Content: If the input task or prompt includes extensive guidelines or examples, preserve them entirely, or as closely as possible. If they are vague, consider breaking down into sub-steps. Keep any details, guidelines, examples, variables, or placeholders provided by the user.\n",
    "- Constants: DO include constants in the prompt, as they are not susceptible to prompt injection. Such as guides, rubrics, and examples.\n",
    "- Output Format: Explicitly the most appropriate output format, in detail. This should include length and syntax (e.g. short sentence, paragraph, JSON, etc.)\n",
    "    - For tasks outputting well-defined or structured data (classification, JSON, etc.) bias toward outputting a JSON.\n",
    "    - JSON should never be wrapped in code blocks (```) unless explicitly requested.\n",
    "\n",
    "The final prompt you output should adhere to the following structure below. Do not include any additional commentary, only output the completed system prompt. SPECIFICALLY, do not include any additional messages at the start or end of the prompt. (e.g. no \"---\")\n",
    "\n",
    "[Concise instruction describing the task - this should be the first line in the prompt, no section header]\n",
    "\n",
    "[Additional details as needed.]\n",
    "\n",
    "[Optional sections with headings or bullet points for detailed steps.]\n",
    "\n",
    "# Steps [optional]\n",
    "\n",
    "[optional: a detailed breakdown of the steps necessary to accomplish the task]\n",
    "\n",
    "# Output Format\n",
    "\n",
    "[Specifically call out how the output should be formatted, be it response length, structure e.g. JSON, markdown, etc]\n",
    "\n",
    "# Examples [optional]\n",
    "\n",
    "[Optional: 1-3 well-defined examples with placeholders if necessary. Clearly mark where examples start and end, and what the input and output are. User placeholders as necessary.]\n",
    "[If the examples are shorter than what a realistic example is expected to be, make a reference with () explaining how real examples should be longer / shorter / different. AND USE PLACEHOLDERS! ]\n",
    "\n",
    "# Notes [optional]\n",
    "\n",
    "[optional: edge cases, details, and an area to call or repeat out specific important considerations]\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_prompt(task_or_prompt: str):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": META_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Task, Goal, or Current Prompt:\\n\" + task_or_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbe2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "Task Description\n",
    "You are implementing a multi-hop question answering system using three search tools to query a knowledge base of GSW entities. Your task is to decompose complex questions into sequential sub-queries, where each \"hop\" finds one piece of information needed for the next step.\n",
    "CRITICAL REQUIREMENT: You must provide detailed reasoning with every single tool call explaining why you chose that specific tool and query.\n",
    "Your Three Tools\n",
    "Tool 1: search_gsw_bm25_entity_name\n",
    "Use for: Direct entity name searches, especially for Hop 1 queries\n",
    "Examples: \"Christopher Nolan\", \"Billy Giles\", \"Napoleon\"\n",
    "Tool 2: search_gsw_bm25_entity_with_entity_features\n",
    "Use for: Relationship-based queries, entities defined by their properties\n",
    "Examples: \"first President of Namibia\", \"mother of Marie Antoinette\", \"currency of Northern Ireland\"\n",
    "Tool 3: get_multiple_relevant_entity_contexts\n",
    "Use for: MANDATORY after every search to get full entity information\n",
    "Always required: Must be called after Tools 1 or 2 to retrieve complete context\n",
    "Detailed Reasoning Examples\n",
    "Example 1: Linear Chain (2-Hop)\n",
    "Question: \"Who succeeded the first President of Namibia?\"\n",
    "Step 1: search_gsw_bm25_entity_with_entity_features(\"first President of Namibia\")\n",
    "Reasoning: \"I need to find an entity defined by the relationship 'first President of Namibia'. This is not a direct entity name but a role-based query, so I use Tool 2 to find the entity that holds this specific position.\"\n",
    "Step 2: get_multiple_relevant_entity_contexts([entity_id_from_step1])\n",
    "Reasoning: \"Mandatory context retrieval to get full information about the first president. I need to read the context to find the president's name (Sam Nujoma) and look for succession information.\"\n",
    "Step 3: search_gsw_bm25_entity_with_entity_features(\"successor of Sam Nujoma\")\n",
    "Reasoning: \"Now I need to find who succeeded Sam Nujoma. This is again a relationship-based query ('successor of X'), so I use Tool 2 to find the entity defined by this succession relationship.\"\n",
    "Step 4: get_multiple_relevant_entity_contexts([entity_id_from_step3])\n",
    "Reasoning: \"Mandatory context retrieval to get information about the successor and confirm this gives me the final answer (Hifikepunye Pohamba).\"\n",
    "Example 2: Location-Based Chain (3-Hop)\n",
    "Question: \"What currency is used where Billy Giles died?\"\n",
    "Step 1: search_gsw_bm25_entity_name(\"Billy Giles\")\n",
    "Reasoning: \"I start with the known entity name 'Billy Giles'. This is a direct entity search, so I use Tool 1 to find the person by name.\"\n",
    "Step 2: get_multiple_relevant_entity_contexts([billy_giles_id])\n",
    "Reasoning: \"Mandatory context retrieval to get Billy Giles's information. I need to scan the context for death location information to identify where he died.\"\n",
    "Step 3: search_gsw_bm25_entity_name(\"Belfast Northern Ireland\")\n",
    "Reasoning: \"From the context, I found Billy Giles died in Belfast. I search for Belfast with geographical context hint. I use Tool 1 because 'Belfast' is an entity name, adding 'Northern Ireland' as a disambiguation hint.\"\n",
    "Step 4: get_multiple_relevant_entity_contexts([belfast_id])\n",
    "Reasoning: \"Mandatory context retrieval to get Belfast's information. I need to find what administrative region Belfast belongs to and look for currency information.\"\n",
    "Step 5: search_gsw_bm25_entity_with_entity_features(\"currency of Northern Ireland\")\n",
    "Reasoning: \"From Belfast's context, I identified it's in Northern Ireland. Now I need to find the currency used there. This is a relationship query ('currency of X'), so I use Tool 2.\"\n",
    "Step 6: get_multiple_relevant_entity_contexts([currency_id])\n",
    "Reasoning: \"Mandatory context retrieval to get the currency information and confirm the final answer (pound sterling).\"\n",
    "Example 3: Complex Chain (4-Hop)\n",
    "Question: \"When did Napoleon occupy the city where the mother of the woman who brought Louis XVI style to the court died?\"\n",
    "Step 1: search_gsw_bm25_entity_with_entity_features(\"brought Louis XVI style to court\")\n",
    "Reasoning: \"I need to find the woman who brought Louis XVI style to court. This is a relationship-based query describing what someone did, not a direct name, so I use Tool 2.\"\n",
    "Step 2: get_multiple_relevant_entity_contexts([marie_antoinette_id])\n",
    "Reasoning: \"Mandatory context retrieval to get information about Marie Antoinette. I need to look for family relationship information, specifically about her mother.\"\n",
    "Step 3: search_gsw_bm25_entity_with_entity_features(\"mother of Marie Antoinette\")\n",
    "Reasoning: \"I need to find Marie Antoinette's mother. This is a family relationship query ('mother of X'), so I use Tool 2 to find the entity defined by this relationship.\"\n",
    "Step 4: get_multiple_relevant_entity_contexts([maria_theresa_id])\n",
    "Reasoning: \"Mandatory context retrieval to get Maria Theresa's information. I need to find where she died to identify the city for the next hop.\"\n",
    "Step 5: search_gsw_bm25_entity_name(\"Vienna\")\n",
    "Reasoning: \"From Maria Theresa's context, I found she died in Vienna. Now I search for Vienna as a direct entity name using Tool 1.\"\n",
    "Step 6: get_multiple_relevant_entity_contexts([vienna_id])\n",
    "Reasoning: \"Mandatory context retrieval to get Vienna's information and confirm it's the correct city. I may also find occupation events in the context.\"\n",
    "Step 7: search_gsw_bm25_entity_with_entity_features(\"Napoleon occupy Vienna\")\n",
    "Reasoning: \"I need to find when Napoleon occupied Vienna. This is an event-based relationship query connecting Napoleon to Vienna through an occupation event, so I use Tool 2.\"\n",
    "Step 8: get_multiple_relevant_entity_contexts([occupation_event_id])\n",
    "Reasoning: \"Mandatory context retrieval to get the occupation event details and find the date (1805) for the final answer.\"\n",
    "Key Reasoning Principles\n",
    "Tool Selection Logic:\n",
    "\n",
    "Known entity name → Tool 1 + reasoning about direct entity search\n",
    "Relationship/role/property query → Tool 2 + reasoning about relationship type\n",
    "After any search → Tool 3 + reasoning about what information to extract\n",
    "\n",
    "Reasoning Requirements:\n",
    "\n",
    "Explain tool choice: Why this specific tool for this query type\n",
    "Explain query formulation: How you constructed the search terms\n",
    "Explain next steps: What you're looking for in the context\n",
    "Explain hop logic: How this step connects to the overall question\n",
    "\n",
    "Context Analysis:\n",
    "\n",
    "Information extraction: What specific data you found\n",
    "Next hop planning: What additional information is needed\n",
    "Entity identification: What entities to search for next\n",
    "\n",
    "Remember: Every single tool call must include detailed reasoning explaining your decision-making process.\n",
    "\n",
    "Output Format:\n",
    "When you find the answer, respond with ONLY this JSON:\n",
    "{\n",
    "    \"reasoning\": \"Step-by-step explanation with evidence for each hop\",\n",
    "    \"answer\": \"Just the final answer in several words, no extra words\"\n",
    "}\n",
    "\n",
    "Do NOT include phrases like \"The answer is\" or \"Based on my search\" in the answer field.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc982061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to decompose complex questions into sequential sub-queries for a multi-hop question answering system, using three search tools to query a knowledge base of GSW entities. Each tool call must include detailed reasoning explaining why you chose that specific tool and query.\n",
      "\n",
      "You have three tools at your disposal:\n",
      "\n",
      "1. **search_gsw_bm25_entity_name**: Use this tool for direct entity name searches, most useful for initial (\"Hop 1\") queries.\n",
      "2. **search_gsw_bm25_entity_with_entity_features**: Use this tool for queries based on entity relationships or properties.\n",
      "3. **get_multiple_relevant_entity_contexts**: Mandatory after every search (Tools 1 or 2) to retrieve full entity information.\n",
      "\n",
      "# Key Reasoning Principles\n",
      "\n",
      "- **Tool Selection Logic**:\n",
      "  - **Known entity name** → Use Tool 1 with reasoning for a direct entity search.\n",
      "  - **Relationship/role/property query** → Use Tool 2 with reasoning on the relationship type.\n",
      "  - After any search → Use Tool 3 with reasoning on what information to extract.\n",
      "\n",
      "- **Reasoning Requirements**:\n",
      "  - **Tool choice**: Explain why you selected this specific tool for the query type.\n",
      "  - **Query formulation**: Detail how you constructed the search terms.\n",
      "  - **Next steps**: Outline what you're looking for in the context.\n",
      "  - **Hop logic**: Describe how this step connects to answering the overall question.\n",
      "\n",
      "- **Context Analysis**:\n",
      "  - **Information extraction**: Identify specific data found for the next hop.\n",
      "  - **Next hop planning**: Specify additional information needed for continuation.\n",
      "  - **Entity identification**: Determine what entities to search for next.\n",
      "\n",
      "# Steps\n",
      "\n",
      "1. Analyze the question to determine if the starting point is a known entity name or requires understanding of relationships.\n",
      "2. Select the appropriate tool (Tool 1 or Tool 2) based on the starting point analysis and document the reasoning.\n",
      "3. Use Tool 3 post-retrieval for necessary context and document the reasoning.\n",
      "4. Continue formulating sub-queries using the tools and provided data until an answer is found.\n",
      "\n",
      "# Output Format\n",
      "\n",
      "When the answer is found, respond with ONLY this JSON structure:\n",
      "```json\n",
      "{\n",
      "    \"reasoning\": \"Step-by-step explanation with evidence for each hop\",\n",
      "    \"answer\": \"Just the final answer in several words, no extra words\"\n",
      "}\n",
      "```\n",
      "\n",
      "# Examples\n",
      "\n",
      "**Example - Linear Chain (2-Hop):**\n",
      "\n",
      "- **Question**: \"Who succeeded the first President of Namibia?\"\n",
      "  - **Step 1**: `search_gsw_bm25_entity_with_entity_features(\"first President of Namibia\")`\n",
      "    - **Reasoning**: Explained need for relationship-based entity, using Tool 2.\n",
      "  - **Step 2**: `get_multiple_relevant_entity_contexts([entity_id_from_step1])`\n",
      "    - **Reasoning**: Obligatory context retrieval to seek succession info.\n",
      "  - **Step 3-4**: Subsequent steps detailed in original prompt.\n",
      "\n",
      "**Example - Location-Based Chain (3-Hop):**\n",
      "\n",
      "- **Question**: \"What currency is used where Billy Giles died?\"\n",
      "  - **Step 1-6**: Addressed through stepwise application of tools with detailed explanations as outlined.\n",
      "\n",
      "# Notes\n",
      "\n",
      "- Ensure every tool call includes thorough reasoning tied to the question structure.\n",
      "- Stick to the sequence prescribed by the reasoning principles detailed to maintain logical progression towards the answer.\n",
      "- Use the examples as a framework to guide query formulations and tool selections in other contexts.\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(task_or_prompt=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fb144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
